{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import MDP\n",
    "import sys\n",
    "\n",
    "''' Construct a simple maze MDP\n",
    "\n",
    "  Grid world layout:\n",
    "\n",
    "  ---------------------\n",
    "  |  0 |  1 |  2 |  3 |\n",
    "  ---------------------\n",
    "  |  4 |  5 |  6 |  7 |\n",
    "  ---------------------\n",
    "  |  8 |  9 | 10 | 11 |\n",
    "  ---------------------\n",
    "  | 12 | 13 | 14 | 15 |\n",
    "  ---------------------\n",
    "\n",
    "  Goal state: 15\n",
    "  Bad state: 9\n",
    "  End state: 16\n",
    "\n",
    "  The end state is an absorbing state that the agent transitions\n",
    "  to after visiting the goal state.\n",
    "\n",
    "  There are 17 states in total (including the end state)\n",
    "  and 4 actions (up, down, left, right).'''\n",
    "\n",
    "# Transition function: |A| x |S| x |S'| array\n",
    "T = np.zeros([4,17,17])\n",
    "a = 0.8;  # intended move\n",
    "b = 0.1;  # lateral move\n",
    "\n",
    "# up (a = 0)\n",
    "\n",
    "T[0,0,0] = a+b;\n",
    "T[0,0,1] = b;\n",
    "\n",
    "T[0,1,0] = b;\n",
    "T[0,1,1] = a;\n",
    "T[0,1,2] = b;\n",
    "\n",
    "T[0,2,1] = b;\n",
    "T[0,2,2] = a;\n",
    "T[0,2,3] = b;\n",
    "\n",
    "T[0,3,2] = b;\n",
    "T[0,3,3] = a+b;\n",
    "\n",
    "T[0,4,4] = b;\n",
    "T[0,4,0] = a;\n",
    "T[0,4,5] = b;\n",
    "\n",
    "T[0,5,4] = b;\n",
    "T[0,5,1] = a;\n",
    "T[0,5,6] = b;\n",
    "\n",
    "T[0,6,5] = b;\n",
    "T[0,6,2] = a;\n",
    "T[0,6,7] = b;\n",
    "\n",
    "T[0,7,6] = b;\n",
    "T[0,7,3] = a;\n",
    "T[0,7,7] = b;\n",
    "\n",
    "T[0,8,8] = b;\n",
    "T[0,8,4] = a;\n",
    "T[0,8,9] = b;\n",
    "\n",
    "T[0,9,8] = b;\n",
    "T[0,9,5] = a;\n",
    "T[0,9,10] = b;\n",
    "\n",
    "T[0,10,9] = b;\n",
    "T[0,10,6] = a;\n",
    "T[0,10,11] = b;\n",
    "\n",
    "T[0,11,10] = b;\n",
    "T[0,11,7] = a;\n",
    "T[0,11,11] = b;\n",
    "\n",
    "T[0,12,12] = b;\n",
    "T[0,12,8] = a;\n",
    "T[0,12,13] = b;\n",
    "\n",
    "T[0,13,12] = b;\n",
    "T[0,13,9] = a;\n",
    "T[0,13,14] = b;\n",
    "\n",
    "T[0,14,13] = b;\n",
    "T[0,14,10] = a;\n",
    "T[0,14,15] = b;\n",
    "\n",
    "T[0,15,16] = 1;\n",
    "T[0,16,16] = 1;\n",
    "\n",
    "# down (a = 1)\n",
    "\n",
    "T[1,0,0] = b;\n",
    "T[1,0,4] = a;\n",
    "T[1,0,1] = b;\n",
    "\n",
    "T[1,1,0] = b;\n",
    "T[1,1,5] = a;\n",
    "T[1,1,2] = b;\n",
    "\n",
    "T[1,2,1] = b;\n",
    "T[1,2,6] = a;\n",
    "T[1,2,3] = b;\n",
    "\n",
    "T[1,3,2] = b;\n",
    "T[1,3,7] = a;\n",
    "T[1,3,3] = b;\n",
    "\n",
    "T[1,4,4] = b;\n",
    "T[1,4,8] = a;\n",
    "T[1,4,5] = b;\n",
    "\n",
    "T[1,5,4] = b;\n",
    "T[1,5,9] = a;\n",
    "T[1,5,6] = b;\n",
    "\n",
    "T[1,6,5] = b;\n",
    "T[1,6,10] = a;\n",
    "T[1,6,7] = b;\n",
    "\n",
    "T[1,7,6] = b;\n",
    "T[1,7,11] = a;\n",
    "T[1,7,7] = b;\n",
    "\n",
    "T[1,8,8] = b;\n",
    "T[1,8,12] = a;\n",
    "T[1,8,9] = b;\n",
    "\n",
    "T[1,9,8] = b;\n",
    "T[1,9,13] = a;\n",
    "T[1,9,10] = b;\n",
    "\n",
    "T[1,10,9] = b;\n",
    "T[1,10,14] = a;\n",
    "T[1,10,11] = b;\n",
    "\n",
    "T[1,11,10] = b;\n",
    "T[1,11,15] = a;\n",
    "T[1,11,11] = b;\n",
    "\n",
    "T[1,12,12] = a+b;\n",
    "T[1,12,13] = b;\n",
    "\n",
    "T[1,13,12] = b;\n",
    "T[1,13,13] = a;\n",
    "T[1,13,14] = b;\n",
    "\n",
    "T[1,14,13] = b;\n",
    "T[1,14,14] = a;\n",
    "T[1,14,15] = b;\n",
    "\n",
    "T[1,15,16] = 1;\n",
    "T[1,16,16] = 1;\n",
    "\n",
    "# left (a = 2)\n",
    "\n",
    "T[2,0,0] = a+b;\n",
    "T[2,0,4] = b;\n",
    "\n",
    "T[2,1,1] = b;\n",
    "T[2,1,0] = a;\n",
    "T[2,1,5] = b;\n",
    "\n",
    "T[2,2,2] = b;\n",
    "T[2,2,1] = a;\n",
    "T[2,2,6] = b;\n",
    "\n",
    "T[2,3,3] = b;\n",
    "T[2,3,2] = a;\n",
    "T[2,3,7] = b;\n",
    "\n",
    "T[2,4,0] = b;\n",
    "T[2,4,4] = a;\n",
    "T[2,4,8] = b;\n",
    "\n",
    "T[2,5,1] = b;\n",
    "T[2,5,4] = a;\n",
    "T[2,5,9] = b;\n",
    "\n",
    "T[2,6,2] = b;\n",
    "T[2,6,5] = a;\n",
    "T[2,6,10] = b;\n",
    "\n",
    "T[2,7,3] = b;\n",
    "T[2,7,6] = a;\n",
    "T[2,7,11] = b;\n",
    "\n",
    "T[2,8,4] = b;\n",
    "T[2,8,8] = a;\n",
    "T[2,8,12] = b;\n",
    "\n",
    "T[2,9,5] = b;\n",
    "T[2,9,8] = a;\n",
    "T[2,9,13] = b;\n",
    "\n",
    "T[2,10,6] = b;\n",
    "T[2,10,9] = a;\n",
    "T[2,10,14] = b;\n",
    "\n",
    "T[2,11,7] = b;\n",
    "T[2,11,10] = a;\n",
    "T[2,11,15] = b;\n",
    "\n",
    "T[2,12,8] = b;\n",
    "T[2,12,12] = a+b;\n",
    "\n",
    "T[2,13,9] = b;\n",
    "T[2,13,12] = a;\n",
    "T[2,13,13] = b;\n",
    "\n",
    "T[2,14,10] = b;\n",
    "T[2,14,13] = a;\n",
    "T[2,14,14] = b;\n",
    "\n",
    "T[2,15,16] = 1;\n",
    "T[2,16,16] = 1;\n",
    "\n",
    "# right (a = 3)\n",
    "\n",
    "T[3,0,0] = b;\n",
    "T[3,0,1] = a;\n",
    "T[3,0,4] = b;\n",
    "\n",
    "T[3,1,1] = b;\n",
    "T[3,1,2] = a;\n",
    "T[3,1,5] = b;\n",
    "\n",
    "T[3,2,2] = b;\n",
    "T[3,2,3] = a;\n",
    "T[3,2,6] = b;\n",
    "\n",
    "T[3,3,3] = a+b;\n",
    "T[3,3,7] = b;\n",
    "\n",
    "T[3,4,0] = b;\n",
    "T[3,4,5] = a;\n",
    "T[3,4,8] = b;\n",
    "\n",
    "T[3,5,1] = b;\n",
    "T[3,5,6] = a;\n",
    "T[3,5,9] = b;\n",
    "\n",
    "T[3,6,2] = b;\n",
    "T[3,6,7] = a;\n",
    "T[3,6,10] = b;\n",
    "\n",
    "T[3,7,3] = b;\n",
    "T[3,7,7] = a;\n",
    "T[3,7,11] = b;\n",
    "\n",
    "T[3,8,4] = b;\n",
    "T[3,8,9] = a;\n",
    "T[3,8,12] = b;\n",
    "\n",
    "T[3,9,5] = b;\n",
    "T[3,9,10] = a;\n",
    "T[3,9,13] = b;\n",
    "\n",
    "T[3,10,6] = b;\n",
    "T[3,10,11] = a;\n",
    "T[3,10,14] = b;\n",
    "\n",
    "T[3,11,7] = b;\n",
    "T[3,11,11] = a;\n",
    "T[3,11,15] = b;\n",
    "\n",
    "T[3,12,8] = b;\n",
    "T[3,12,13] = a;\n",
    "T[3,12,12] = b;\n",
    "\n",
    "T[3,13,9] = b;\n",
    "T[3,13,14] = a;\n",
    "T[3,13,13] = b;\n",
    "\n",
    "T[3,14,10] = b;\n",
    "T[3,14,15] = a;\n",
    "T[3,14,14] = b;\n",
    "\n",
    "T[3,15,16] = 1;\n",
    "T[3,16,16] = 1;\n",
    "\n",
    "# Reward function: |A| x |S| array\n",
    "R = -1 * np.ones([4,17]);\n",
    "\n",
    "# set rewards\n",
    "R[:,15] = 100;  # goal state\n",
    "R[:,9] = -70;   # bad state\n",
    "R[:,16] = 0;    # end state\n",
    "\n",
    "# Discount factor: scalar in [0,1)\n",
    "discount = 0.95\n",
    "\n",
    "# MDP object\n",
    "mdp = MDP.MDP(T,R,discount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ tolerance:0.01 ---------------------------\n",
      "[DEBUG] valueIteration nIterations: 20, epsilon: 0.008079508521525725\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.62388836   66.03486523   71.80422632   77.09196339   59.81429704\n",
      "   65.18237783   77.83066489   84.14118981   58.09361039    7.98780239\n",
      "   84.86704922   91.78159355   69.49584217   76.80962081   91.78159355\n",
      "  100.            0.        ]\n",
      "------------------------ tolerance:0.0 ---------------------------\n",
      "[DEBUG] valueIteration nIterations: 62, epsilon: 0.0\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.63256172   66.03897428   71.8062328    77.09295576   59.81945165\n",
      "   65.18457679   77.83151901   84.14149059   58.0955782     7.98862928\n",
      "   84.86730581   91.78165089   69.4968138    76.80991653   91.78165089\n",
      "  100.            0.        ]\n"
     ]
    }
   ],
   "source": [
    "'''Test each procedure'''\n",
    "[V,nIterations,epsilon] = mdp.valueIteration(initialV=np.zeros(mdp.nStates),tolerance=0.01)\n",
    "policy = mdp.extractPolicy(V)\n",
    "print (\"------------------------ tolerance:0.01 ---------------------------\")\n",
    "print (\"[DEBUG] valueIteration nIterations: {}, epsilon: {}\".format(nIterations,epsilon))\n",
    "print (\"policy:\")\n",
    "print (policy)\n",
    "print (\"V:\")\n",
    "print (V)\n",
    "[V,nIterations,epsilon] = mdp.valueIteration(initialV=np.zeros(mdp.nStates),tolerance=0.0)\n",
    "policy = mdp.extractPolicy(V)\n",
    "print (\"------------------------ tolerance:0.0 ---------------------------\")\n",
    "print (\"[DEBUG] valueIteration nIterations: {}, epsilon: {}\".format(nIterations,epsilon))\n",
    "print (\"policy:\")\n",
    "print (policy)\n",
    "print (\"V:\")\n",
    "print (V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "[DEBUG] policyIteration nIterations: 5\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.63256172   66.03897428   71.8062328    77.09295576   59.81945165\n",
      "   65.18457679   77.83151901   84.14149059   58.0955782     7.98862928\n",
      "   84.86730581   91.78165089   69.4968138    76.80991653   91.78165089\n",
      "  100.            0.        ]\n"
     ]
    }
   ],
   "source": [
    "[policy,V,nIterations] = mdp.policyIteration(np.zeros(mdp.nStates,dtype=int))\n",
    "print (\"----------------------------------------------------------------\")\n",
    "print (\"[DEBUG] policyIteration nIterations: {}\".format(nIterations))\n",
    "print (\"policy:\")\n",
    "print (policy)\n",
    "print (\"V:\")\n",
    "print (V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Original ------------------------------\n",
      "[DEBUG] modifiedPolicyIteration nIterations: 6, epsilon: 0.004589924537079071\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.62299224   66.03435705   71.80403745   77.09184077   59.81354253\n",
      "   65.18219837   77.83055148   84.1411644    58.09343024    7.98767806\n",
      "   84.86703052   91.78158579   69.49571217   76.80959703   91.78158579\n",
      "  100.            0.        ]\n",
      "------------------------ nEvalIterations:inf ----------------------\n",
      "[DEBUG] modifiedPolicyIteration nIterations: 5, epsilon: 0.0\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.63256172   66.03897428   71.8062328    77.09295576   59.81945165\n",
      "   65.18457679   77.83151901   84.14149059   58.0955782     7.98862928\n",
      "   84.86730581   91.78165089   69.4968138    76.80991653   91.78165089\n",
      "  100.            0.        ]\n",
      "------------------------ nEvalIterations:0 ------------------------\n",
      "[DEBUG] modifiedPolicyIteration nIterations: 20, epsilon: 0.008079508521525725\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.61580885   66.03092825   71.80235877   77.09101022   59.8092742\n",
      "   65.18036197   77.82983656   84.14091229   58.09179053    7.98698803\n",
      "   84.86681543   91.78153772   69.4949032    76.80935036   91.78153772\n",
      "  100.            0.        ]\n",
      "------------------ nEvalIterations:0,tolerenace:0.0 ---------------\n",
      "[DEBUG] modifiedPolicyIteration nIterations: 62, epsilon: 0.0\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.63256172   66.03897428   71.8062328    77.09295576   59.81945165\n",
      "   65.18457679   77.83151901   84.14149059   58.0955782     7.98862928\n",
      "   84.86730581   91.78165089   69.4968138    76.80991653   91.78165089\n",
      "  100.            0.        ]\n"
     ]
    }
   ],
   "source": [
    "[policy,V,nIterations,epsilon] = mdp.modifiedPolicyIteration(np.zeros(mdp.nStates,dtype=int),np.zeros(mdp.nStates),tolerance=0.01)\n",
    "print (\"--------------------------- Original ------------------------------\")\n",
    "print (\"[DEBUG] modifiedPolicyIteration nIterations: {}, epsilon: {}\".format(nIterations,epsilon))\n",
    "print (\"policy:\")\n",
    "print (policy)\n",
    "print (\"V:\")\n",
    "print (V)\n",
    "#policy iteration using modified policy iteration\n",
    "[policy,V,nIterations,epsilon] = mdp.modifiedPolicyIteration(np.zeros(mdp.nStates,dtype=int),np.zeros(mdp.nStates),tolerance=0.0,nEvalIterations=np.inf)\n",
    "print (\"------------------------ nEvalIterations:inf ----------------------\")\n",
    "print (\"[DEBUG] modifiedPolicyIteration nIterations: {}, epsilon: {}\".format(nIterations,epsilon))\n",
    "print (\"policy:\")\n",
    "print (policy)\n",
    "print (\"V:\")\n",
    "print (V)\n",
    "#value iteration using modified policy iteration\n",
    "[policy,V,nIterations,epsilon] = mdp.modifiedPolicyIteration(np.zeros(mdp.nStates,dtype=int),np.zeros(mdp.nStates),tolerance=0.01,nEvalIterations=0)\n",
    "print (\"------------------------ nEvalIterations:0 ------------------------\")\n",
    "print (\"[DEBUG] modifiedPolicyIteration nIterations: {}, epsilon: {}\".format(nIterations,epsilon))\n",
    "print (\"policy:\")\n",
    "print (policy)\n",
    "print (\"V:\")\n",
    "print (V)\n",
    "[policy,V,nIterations,epsilon] = mdp.modifiedPolicyIteration(np.zeros(mdp.nStates,dtype=int),np.zeros(mdp.nStates),tolerance=0.0,nEvalIterations=0)\n",
    "print (\"------------------ nEvalIterations:0,tolerenace:0.0 ---------------\")\n",
    "print (\"[DEBUG] modifiedPolicyIteration nIterations: {}, epsilon: {}\".format(nIterations,epsilon))\n",
    "print (\"policy:\")\n",
    "print (policy)\n",
    "print (\"V:\")\n",
    "print (V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- nEvalIterations: 1 ---------------------\n",
      "[DEBUG] modifiedPolicyIteration nIterations: 11, epsilon: 0.0027812914590654714\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.62684254   66.03625179   71.80491036   77.09229804   59.81602563\n",
      "   65.18313123   77.83095193   84.14129267   58.09428458    7.98807868\n",
      "   84.86713734   91.78161279   69.49616973   76.80972221   91.78161279\n",
      "  100.            0.        ]\n",
      "---------------------- nEvalIterations: 2 ---------------------\n",
      "[DEBUG] modifiedPolicyIteration nIterations: 8, epsilon: 0.0032342488432277605\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.62585588   66.03575432   71.80468363   77.09217736   59.81537412\n",
      "   65.18289152   77.83084576   84.14125941   58.0940612     7.98797218\n",
      "   84.86710983   91.78160561   69.49604825   76.80969016   91.78160561\n",
      "  100.            0.        ]\n",
      "---------------------- nEvalIterations: 3 ---------------------\n",
      "[DEBUG] modifiedPolicyIteration nIterations: 7, epsilon: 0.0031580695780704104\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.62598181   66.03579895   71.80471467   77.09218806   59.8154148\n",
      "   65.18293008   77.83085372   84.14126451   58.09409758    7.98797768\n",
      "   84.86711465   91.78160611   69.49605907   76.80969544   91.78160611\n",
      "  100.            0.        ]\n",
      "---------------------- nEvalIterations: 4 ---------------------\n",
      "[DEBUG] modifiedPolicyIteration nIterations: 6, epsilon: 0.003027387506065793\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.62624063   66.03591602   71.80477257   77.09221603   59.8155682\n",
      "   65.18299451   77.83087761   84.14127319   58.0941738     7.98800074\n",
      "   84.86712212   91.78160771   69.49609329   76.80970412   91.78160771\n",
      "  100.            0.        ]\n",
      "---------------------- nEvalIterations: 5 ---------------------\n",
      "[DEBUG] modifiedPolicyIteration nIterations: 6, epsilon: 0.004589924537079071\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.62299224   66.03435705   71.80403745   77.09184077   59.81354253\n",
      "   65.18219837   77.83055148   84.1411644    58.09343024    7.98767806\n",
      "   84.86703052   91.78158579   69.49571217   76.80959703   91.78158579\n",
      "  100.            0.        ]\n",
      "---------------------- nEvalIterations: 6 ---------------------\n",
      "[DEBUG] modifiedPolicyIteration nIterations: 5, epsilon: 0.009178473775094176\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.61419017   66.03046876   71.80194603   77.09090128   59.80909815\n",
      "   65.17981566   77.82976844   84.14084126   58.09168523    7.98696493\n",
      "   84.86674518   91.78153367   69.4949331    76.80927337   91.78153367\n",
      "  100.            0.        ]\n",
      "---------------------- nEvalIterations: 7 ---------------------\n",
      "[DEBUG] modifiedPolicyIteration nIterations: 5, epsilon: 0.003222591598593283\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.62583573   66.03571516   71.80466505   77.09216558   59.81537267\n",
      "   65.18287589   77.83083494   84.14125638   58.0941632     7.98796204\n",
      "   84.86710745   91.78160479   69.4960796    76.80968778   91.78160479\n",
      "  100.            0.        ]\n",
      "---------------------- nEvalIterations: 8 ---------------------\n",
      "[DEBUG] modifiedPolicyIteration nIterations: 5, epsilon: 0.004842963564485103\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.62273645   66.03438075   71.80400518   77.09185169   59.81357977\n",
      "   65.18212984   77.83056808   84.1411579    58.09335378    7.98770168\n",
      "   84.86702234   91.78158719   69.49570851   76.80958576   91.78158719\n",
      "  100.            0.        ]\n",
      "---------------------- nEvalIterations: 9 ---------------------\n",
      "[DEBUG] modifiedPolicyIteration nIterations: 5, epsilon: 0.0045562197431223694\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.62338108   66.03471559   71.80415359   77.09193316   59.81402364\n",
      "   65.1822841    77.83064037   84.14117947   58.09349675    7.98777512\n",
      "   84.86703994   91.78159211   69.49579015   76.80960634   91.78159211\n",
      "  100.            0.        ]\n",
      "---------------------- nEvalIterations: 10 ---------------------\n",
      "[DEBUG] modifiedPolicyIteration nIterations: 5, epsilon: 0.004345785880865094\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.62378296   66.03489102   71.80424602   77.09197509   59.81423362\n",
      "   65.18238949   77.83067544   84.14119361   58.09358664    7.98780756\n",
      "   84.86705237   91.78159443   69.49582971   76.80962058   91.78159443\n",
      "  100.            0.        ]\n",
      "nIterations List: [11, 8, 7, 6, 6, 5, 5, 5, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "#this cell counts the number of policy iteration steps required\n",
    "nIterations_list = []\n",
    "for nEvalIterations in range(1, 11):\n",
    "    [policy,V,nIterations,epsilon] = mdp.modifiedPolicyIteration(np.zeros(mdp.nStates,dtype=int),np.zeros(mdp.nStates),nEvalIterations=nEvalIterations,tolerance=0.01)\n",
    "    nIterations_list.append(nIterations)\n",
    "    #print (\"nEvalIterations: {}, nIterations: {}\".format(nEvalIterations, nIterations))\n",
    "    print (\"---------------------- nEvalIterations: {} ---------------------\".format(nEvalIterations))\n",
    "    print (\"[DEBUG] modifiedPolicyIteration nIterations: {}, epsilon: {}\".format(nIterations,epsilon))\n",
    "    print (\"policy:\")\n",
    "    print (policy)\n",
    "    print (\"V:\")\n",
    "    print (V)\n",
    "print (\"nIterations List: {}\".format(nIterations_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- nEvalIterations: 1 ---------------------\n",
      "[DEBUG] modifiedPolicyIteration nIterations_all: 22, epsilon: 0.0027812914590654714\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.62684254   66.03625179   71.80491036   77.09229804   59.81602563\n",
      "   65.18313123   77.83095193   84.14129267   58.09428458    7.98807868\n",
      "   84.86713734   91.78161279   69.49616973   76.80972221   91.78161279\n",
      "  100.            0.        ]\n",
      "---------------------- nEvalIterations: 2 ---------------------\n",
      "[DEBUG] modifiedPolicyIteration nIterations_all: 24, epsilon: 0.0032342488432277605\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.62585588   66.03575432   71.80468363   77.09217736   59.81537412\n",
      "   65.18289152   77.83084576   84.14125941   58.0940612     7.98797218\n",
      "   84.86710983   91.78160561   69.49604825   76.80969016   91.78160561\n",
      "  100.            0.        ]\n",
      "---------------------- nEvalIterations: 3 ---------------------\n",
      "[DEBUG] modifiedPolicyIteration nIterations_all: 27, epsilon: 0.0031580695780704104\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.62598181   66.03579895   71.80471467   77.09218806   59.8154148\n",
      "   65.18293008   77.83085372   84.14126451   58.09409758    7.98797768\n",
      "   84.86711465   91.78160611   69.49605907   76.80969544   91.78160611\n",
      "  100.            0.        ]\n",
      "---------------------- nEvalIterations: 4 ---------------------\n",
      "[DEBUG] modifiedPolicyIteration nIterations_all: 30, epsilon: 0.003027387506065793\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.62624063   66.03591602   71.80477257   77.09221603   59.8155682\n",
      "   65.18299451   77.83087761   84.14127319   58.0941738     7.98800074\n",
      "   84.86712212   91.78160771   69.49609329   76.80970412   91.78160771\n",
      "  100.            0.        ]\n",
      "---------------------- nEvalIterations: 5 ---------------------\n",
      "[DEBUG] modifiedPolicyIteration nIterations_all: 33, epsilon: 0.004589924537079071\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.62299224   66.03435705   71.80403745   77.09184077   59.81354253\n",
      "   65.18219837   77.83055148   84.1411644    58.09343024    7.98767806\n",
      "   84.86703052   91.78158579   69.49571217   76.80959703   91.78158579\n",
      "  100.            0.        ]\n",
      "---------------------- nEvalIterations: 6 ---------------------\n",
      "[DEBUG] modifiedPolicyIteration nIterations_all: 35, epsilon: 0.009178473775094176\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.61419017   66.03046876   71.80194603   77.09090128   59.80909815\n",
      "   65.17981566   77.82976844   84.14084126   58.09168523    7.98696493\n",
      "   84.86674518   91.78153367   69.4949331    76.80927337   91.78153367\n",
      "  100.            0.        ]\n",
      "---------------------- nEvalIterations: 7 ---------------------\n",
      "[DEBUG] modifiedPolicyIteration nIterations_all: 40, epsilon: 0.003222591598593283\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.62583573   66.03571516   71.80466505   77.09216558   59.81537267\n",
      "   65.18287589   77.83083494   84.14125638   58.0941632     7.98796204\n",
      "   84.86710745   91.78160479   69.4960796    76.80968778   91.78160479\n",
      "  100.            0.        ]\n",
      "---------------------- nEvalIterations: 8 ---------------------\n",
      "[DEBUG] modifiedPolicyIteration nIterations_all: 44, epsilon: 0.004842963564485103\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.62273645   66.03438075   71.80400518   77.09185169   59.81357977\n",
      "   65.18212984   77.83056808   84.1411579    58.09335378    7.98770168\n",
      "   84.86702234   91.78158719   69.49570851   76.80958576   91.78158719\n",
      "  100.            0.        ]\n",
      "---------------------- nEvalIterations: 9 ---------------------\n",
      "[DEBUG] modifiedPolicyIteration nIterations_all: 48, epsilon: 0.0045562197431223694\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.62338108   66.03471559   71.80415359   77.09193316   59.81402364\n",
      "   65.1822841    77.83064037   84.14117947   58.09349675    7.98777512\n",
      "   84.86703994   91.78159211   69.49579015   76.80960634   91.78159211\n",
      "  100.            0.        ]\n",
      "---------------------- nEvalIterations: 10 ---------------------\n",
      "[DEBUG] modifiedPolicyIteration nIterations_all: 52, epsilon: 0.004345785880865094\n",
      "policy:\n",
      "[3 3 3 1 3 3 3 1 1 3 3 1 3 3 3 0 0]\n",
      "V:\n",
      "[  60.62378296   66.03489102   71.80424602   77.09197509   59.81423362\n",
      "   65.18238949   77.83067544   84.14119361   58.09358664    7.98780756\n",
      "   84.86705237   91.78159443   69.49582971   76.80962058   91.78159443\n",
      "  100.            0.        ]\n",
      "nIterations Complete List: [22, 24, 27, 30, 33, 35, 40, 44, 48, 52]\n"
     ]
    }
   ],
   "source": [
    "#this cell counts the total number of steps required (policy iteration + value function evaluation)\n",
    "nIterations_full_list = []\n",
    "for nEvalIterations in range(1, 11):\n",
    "    [policy,V,nIterations,epsilon] = mdp.modifiedPolicyIteration(np.zeros(mdp.nStates,dtype=int),np.zeros(mdp.nStates),nEvalIterations=nEvalIterations,tolerance=0.01, report_full_iter=True)\n",
    "    nIterations_full_list.append(nIterations)\n",
    "    #print (\"nEvalIterations: {}, nIterations_all: {}\".format(nEvalIterations, nIterations))\n",
    "    print (\"---------------------- nEvalIterations: {} ---------------------\".format(nEvalIterations))\n",
    "    print (\"[DEBUG] modifiedPolicyIteration nIterations_all: {}, epsilon: {}\".format(nIterations,epsilon))\n",
    "    print (\"policy:\")\n",
    "    print (policy)\n",
    "    print (\"V:\")\n",
    "    print (V)\n",
    "print (\"nIterations Complete List: {}\".format(nIterations_full_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell shows the result of running Modified Policy Iteration with different values of `nEvalIterations`. `nIterations List`$=[11, 8, 7, 6, 6, 5, 5, 5, 5, 5]$ shows the number of iterations of policy iteration step which were executed. `nIterations Complete List`$=[22, 24, 27, 30, 33, 35, 40, 44, 48, 52]$ also includes the total number of value function evaluation steps which were executed alongside policy iteration steps. When `nEvalIterations=1`, the partial policy iteration only runs once and thus is not able to converge fast and thus we see that modified policy iteration takes 11 steps. As the value of `nEvalIterations` increases the number of policy iteration steps decreases quickly to 5. We see from `Q2` results that 5 is the least amount of steps required to converge to optimal policy and we won't get nIterations lower than 5. Looking at the output of `nIterations Complete List`, we see that even though the number of policy iteration steps stay constant at 5 for `nEvalIterations>5`, the total number of policy + value evaluation steps (almost linearly) keep increasing.\n",
    "Looking at the running time of Modified Policy Iteration:\n",
    "$$O(k|S|^2 + |S|^2|A|)$$\n",
    "where k is the number of partial policy evaluations. From the above analysis it is important to run cross-validation techniques for hyper-parameter estimation for k. If k is too small, then we would run extra steps of policy iteration (which has a running time of cubic in the number of states per iteration) and if k is too large, then we would run extra steps of value function evaluation (which would result in $|S|^2|A|$ running time factor per iteration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

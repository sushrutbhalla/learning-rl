{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MDP import *\n",
    "\n",
    "''' Construct simple MDP as described in Lecture 2a Slides 13-14'''\n",
    "# Transition function: |A| x |S| x |S'| array\n",
    "T = np.array([[[0.5,0.5,0,0],[0,1,0,0],[0.5,0.5,0,0],[0,1,0,0]],[[1,0,0,0],[0.5,0,0,0.5],[0.5,0,0.5,0],[0,0,0.5,0.5]]])\n",
    "# Reward function: |A| x |S| array\n",
    "R = np.array([[0,0,10,10],[0,0,10,10]])\n",
    "# Discount factor: scalar in [0,1)\n",
    "discount = 0.9\n",
    "# MDP object\n",
    "mdp = MDP(T,R,discount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Iteration with Extract Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] valueIteration: [array([ 31.49636306,  38.51527513,  43.935435  ,  54.1128575 ]), 58, 0.0098601388198389373]\n",
      "[DEBUG] extractPolicy: [0 1 1 1]\n",
      "[DEBUG] valueIteration: [array([ 31.58510431,  38.60401638,  44.02417625,  54.20159875]), 336, 0.0]\n",
      "[DEBUG] extractPolicy: [0 1 1 1]\n",
      "[DEBUG] valueIteration: [array([ 31.49636306,  38.51527513,  43.935435  ,  54.1128575 ]), 58, 0.0098601388198389373]\n",
      "[DEBUG] extractPolicy: [0 1 1 1]\n",
      "[DEBUG] valueIteration: [array([ 31.58404185,  38.60295392,  44.0231138 ,  54.2005363 ]), 100, 0.00011805066172598799]\n",
      "[DEBUG] extractPolicy: [0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "'''Test each procedure'''\n",
    "[V,nIterations,epsilon] = mdp.valueIteration(initialV=np.zeros(mdp.nStates))\n",
    "print (\"[DEBUG] valueIteration: {}\".format([V,nIterations,epsilon]))\n",
    "policy = mdp.extractPolicy(V)\n",
    "print (\"[DEBUG] extractPolicy: {}\".format(policy))\n",
    "[V,nIterations,epsilon] = mdp.valueIteration(initialV=np.zeros(mdp.nStates),tolerance=0.0)\n",
    "print (\"[DEBUG] valueIteration: {}\".format([V,nIterations,epsilon]))\n",
    "policy = mdp.extractPolicy(V)\n",
    "print (\"[DEBUG] extractPolicy: {}\".format(policy))\n",
    "[V,nIterations,epsilon] = mdp.valueIteration(initialV=np.zeros(mdp.nStates),nIterations=100)\n",
    "print (\"[DEBUG] valueIteration: {}\".format([V,nIterations,epsilon]))\n",
    "policy = mdp.extractPolicy(V)\n",
    "print (\"[DEBUG] extractPolicy: {}\".format(policy))\n",
    "[V,nIterations,epsilon] = mdp.valueIteration(initialV=np.zeros(mdp.nStates),nIterations=100,tolerance=0.0)\n",
    "print (\"[DEBUG] valueIteration: {}\".format([V,nIterations,epsilon]))\n",
    "policy = mdp.extractPolicy(V)\n",
    "print (\"[DEBUG] extractPolicy: {}\".format(policy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] evaluatePolicy: [  0.           0.          18.18181818  10.        ]\n",
      "[DEBUG] evaluatePolicy: [  0.   0.  10.  10.]\n",
      "[DEBUG] evaluatePolicy: [  0.           7.56302521  18.18181818  16.80672269]\n",
      "[DEBUG] evaluatePolicy: [ 31.58510431  38.60401638  44.02417625  54.20159875]\n"
     ]
    }
   ],
   "source": [
    "V = mdp.evaluatePolicy(np.array([1,0,1,0]))\n",
    "print (\"[DEBUG] evaluatePolicy: {}\".format(V))\n",
    "V = mdp.evaluatePolicy(np.array([1,0,0,0]))\n",
    "print (\"[DEBUG] evaluatePolicy: {}\".format(V))\n",
    "V = mdp.evaluatePolicy(np.array([1,1,1,0]))\n",
    "print (\"[DEBUG] evaluatePolicy: {}\".format(V))\n",
    "V = mdp.evaluatePolicy(np.array([0,1,1,1]))\n",
    "print (\"[DEBUG] evaluatePolicy: {}\".format(V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] policyIteration: [array([0, 1, 1, 1], dtype=int64), array([ 31.58510431,  38.60401638,  44.02417625,  54.20159875]), 2]\n",
      "[DEBUG] policyIteration: [array([0, 1, 1, 1], dtype=int64), array([ 31.58510431,  38.60401638,  44.02417625,  54.20159875]), 2]\n",
      "[DEBUG] policyIteration: [array([0, 1, 1, 1], dtype=int64), array([ 31.58510431,  38.60401638,  44.02417625,  54.20159875]), 2]\n"
     ]
    }
   ],
   "source": [
    "[policy,V,iterId] = mdp.policyIteration(np.array([0,0,0,0]))\n",
    "print (\"[DEBUG] policyIteration: {}\".format([policy,V,iterId]))\n",
    "[policy,V,iterId] = mdp.policyIteration(np.array([1,0,0,0]))\n",
    "print (\"[DEBUG] policyIteration: {}\".format([policy,V,iterId]))\n",
    "[policy,V,iterId] = mdp.policyIteration(np.array([1,1,1,0]))\n",
    "print (\"[DEBUG] policyIteration: {}\".format([policy,V,iterId]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial Policy Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] evaluatePolicyPartially: [array([  0.        ,   0.08727964,  18.18181818,  10.08727964]), 45, 0.0096977372978752641]\n",
      "[DEBUG] evaluatePolicyPartially: [array([  0.08727964,   7.65030482,  18.26909782,  16.89400229]), 45, 0.0096977372978752363]\n"
     ]
    }
   ],
   "source": [
    "[V,iterId,epsilon] = mdp.evaluatePolicyPartially(np.array([1,0,1,0]),np.array([0,10,0,13]))\n",
    "print (\"[DEBUG] evaluatePolicyPartially: {}\".format([V,iterId,epsilon]))\n",
    "[V,iterId,epsilon] = mdp.evaluatePolicyPartially(np.array([1,1,1,0]),np.array([10,0,15,1]))\n",
    "print (\"[DEBUG] evaluatePolicyPartially: {}\".format([V,iterId,epsilon]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified Policy Iteration\n",
    "The following code shows results for running modified policy iteration with `nEvalIterations` set to $\\inf$ to achieve the same behavior as Policy Iterations. The results also match as the number of iterations to converge to optimal policy is $2$. I also set the value of `nEvalIterations` to $0$ and we see that the number of iterations till convergence matches the results from value iterations: $336$ and $58$ with $\\epsilon=0.0,0.01$ respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] modifiedPolicyIteration: [array([0, 1, 1, 1], dtype=int64), array([ 31.49727025,  38.51618232,  43.9363422 ,  54.1137647 ]), 11, 0.0087834054981215104]\n",
      "[DEBUG] modifiedPolicyIteration: [array([0, 1, 1, 1], dtype=int64), array([ 31.49636306,  38.51527513,  43.935435  ,  54.1128575 ]), 29, 0.0088741249378472276]\n",
      "POLICY ITERATION\n",
      "[DEBUG] modifiedPolicyIteration: [array([0, 1, 1, 1], dtype=int64), array([ 31.50048281,  38.51939488,  43.93955476,  54.11697725]), 2, 0.00846214972925452]\n",
      "[DEBUG] modifiedPolicyIteration: [array([0, 1, 1, 1], dtype=int64), array([ 31.58510431,  38.60401638,  44.02417625,  54.20159875]), 2, 0.0]\n",
      "VALUE ITERATION\n",
      "[DEBUG] modifiedPolicyIteration: [array([0, 1, 1, 1], dtype=int64), array([ 31.58510431,  38.60401638,  44.02417625,  54.20159875]), 336, 0.0]\n",
      "[DEBUG] modifiedPolicyIteration: [array([0, 1, 1, 1], dtype=int64), array([ 31.48650292,  38.50541499,  43.92557486,  54.10299736]), 58, 0.0098601388198389373]\n"
     ]
    }
   ],
   "source": [
    "[policy,V,iterId,tolerance] = mdp.modifiedPolicyIteration(np.array([1,0,1,0]),np.array([0,10,0,13]))\n",
    "print (\"[DEBUG] modifiedPolicyIteration: {}\".format([policy,V,iterId,tolerance]))\n",
    "[policy,V,iterId,tolerance] = mdp.modifiedPolicyIteration(np.array([1,0,1,0]),np.array([0,10,0,13]),nEvalIterations=1)\n",
    "print (\"[DEBUG] modifiedPolicyIteration: {}\".format([policy,V,iterId,tolerance]))\n",
    "#Policy Iteration using Modified Policy Iteration (nEvalIterations=infinite)\n",
    "print (\"POLICY ITERATION\")\n",
    "[policy,V,iterId,tolerance] = mdp.modifiedPolicyIteration(np.array([1,0,1,0]),np.array([0,10,0,13]),nEvalIterations=np.inf)\n",
    "print (\"[DEBUG] modifiedPolicyIteration: {}\".format([policy,V,iterId,tolerance]))\n",
    "[policy,V,iterId,tolerance] = mdp.modifiedPolicyIteration(np.zeros(mdp.nStates,dtype=int),np.zeros(mdp.nStates),nEvalIterations=np.inf, tolerance=0.0)\n",
    "print (\"[DEBUG] modifiedPolicyIteration: {}\".format([policy,V,iterId,tolerance]))\n",
    "#Value Iteration using Modified Policy Iteration (nEvalIterations=0)\n",
    "print (\"VALUE ITERATION\")\n",
    "[policy,V,iterId,tolerance] = mdp.modifiedPolicyIteration(np.zeros(mdp.nStates,dtype=int),np.zeros(mdp.nStates),nEvalIterations=0, tolerance=0.0)\n",
    "print (\"[DEBUG] modifiedPolicyIteration: {}\".format([policy,V,iterId,tolerance]))\n",
    "[policy,V,iterId,tolerance] = mdp.modifiedPolicyIteration(np.zeros(mdp.nStates,dtype=int),np.zeros(mdp.nStates),nEvalIterations=0)\n",
    "print (\"[DEBUG] modifiedPolicyIteration: {}\".format([policy,V,iterId,tolerance]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

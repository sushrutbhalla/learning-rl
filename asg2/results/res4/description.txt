next keep Gn
and make learning rate linearly decaying
lr = 0.01*int((nEpisodes-episode_idx)/(nEpisodes/10)+1)
all the previous ones have epsilon=0.0 and this one

results:
REINFORCE results
[[  1.39251297e-02   7.95379237e-04   1.59534611e-02   1.46049033e-02
    9.99998452e-01   3.85023636e-04   6.51816886e-03   9.57740513e-04
    2.43567150e-01   1.30646707e-02   1.35819340e-03   8.91899043e-04
    2.04038524e-01   9.86716740e-01   2.63898054e-04   9.93325622e-01
    3.64432502e-02]
 [  9.83141208e-01   9.97691251e-01   1.01024549e-02   9.59031752e-01
    3.19058350e-07   3.48185756e-04   9.69685300e-01   9.96823371e-01
    4.15164865e-01   1.53743744e-03   9.71157560e-01   9.05602268e-04
    3.99447349e-01   4.37714666e-03   2.34091938e-04   7.49835976e-04
    1.25954854e-01]
 [  2.13889381e-03   8.15922755e-04   9.56973813e-01   1.01483520e-02
    1.20608714e-06   3.17251002e-04   2.99148016e-03   1.16336733e-03
    2.56530582e-01   1.67105226e-03   1.37938875e-03   9.97489221e-01
    2.25420651e-01   4.49215517e-03   2.20060146e-04   8.55524867e-04
    6.19828730e-01]
 [  7.94768369e-04   6.97447370e-04   1.69702705e-02   1.62149925e-02
    2.32186662e-08   9.98949540e-01   2.08050514e-02   1.05552114e-03
    8.47374031e-02   9.83726840e-01   2.61048574e-02   7.13277547e-04
    1.71093477e-01   4.41395834e-03   9.99281950e-01   5.06901711e-03
    2.17773166e-01]]
rounded policy:
[[ 0.   0.   0.   0.   1.   0.   0.   0.   0.2  0.   0.   0.   0.2  1.   0.
   1.   0. ]
 [ 1.   1.   0.   1.   0.   0.   1.   1.   0.4  0.   1.   0.   0.4  0.   0.
   0.   0.1]
 [ 0.   0.   1.   0.   0.   0.   0.   0.   0.3  0.   0.   1.   0.2  0.   0.
   0.   0.6]
 [ 0.   0.   0.   0.   0.   1.   0.   0.   0.1  1.   0.   0.   0.2  0.   1.
   0.   0.2]]
argmax policy:
[1 1 2 1 0 3 1 1 1 3 1 2 1 0 3 0 2]
TERMINATE: True, GOODNESS: False, SOFT_GOODNESS: False
bad states: [2, 4, 11, 12, 13], Total Reward: 87.15280684560783, Total Steps to terminate: 13
['0:down', '1:down', '2:left', '3:down', '4:up', '5:right', '6:down', '7:down', '8:down', '9:right', '10:down', '11:left', '12:down', '13:up', '14:right', '15:up', '16:le
ft']
Number of terminations: 100
last 10 episode rewards: [ 11.41210953  31.00557862  43.55322727  59.62736754  64.34021168
  55.24844262  44.5553789   -6.96817656   6.35613122 -15.22326911]

model-based RL results
[  61.14981961   66.49192535   72.56757388   77.51978042   59.98579411
   65.76892957   78.56481126   84.60530399   53.05717716   10.79467197
   86.0113574    92.28850693   48.6212401    87.48820813   93.76466979
  100.51525501    0.39796687]
[3 3 1 1 3 3 3 1 0 3 3 1 0 3 3 3 0]
rounded policy:
[3 3 1 1 3 3 3 1 0 3 3 1 0 3 3 3 0]
TERMINATE: True, GOODNESS: False, SOFT_GOODNESS: True
bad states: [12], Total Reward: 99.21872607967859, Total Steps to terminate: 7
['0:right', '1:right', '2:down', '3:down', '4:right', '5:right', '6:right', '7:down', '8:up', '9:right', '10:right', '11:down', '12:up', '13:right', '14:right', '15:right
', '16:up']

Q-learning results
[[  -0.67826311    2.44658243   -2.56741312   -3.16848579   -0.71872506
     0.52865899   11.74192503   -1.77581292   -9.77357135  -71.95763947
     0.58173489   -1.31572823   -1.86834508  -34.54944196   27.63753569
   100.78180245    0.66340708]
 [   0.13430039   23.32352497   21.72385695   -2.30463485   -2.79266134
   -18.78142582   49.99150149   38.39948639   -6.81681871  -46.24067288
    67.95105358   46.54322229   11.80887386   -1.97087079   65.33528359
   100.68680262    0.66209746]
 [  -1.85232402    4.14671613   10.0435922     2.41211341   -2.78833042
     0.19300547   16.64869576   13.56395033   -1.77454894  -72.14074541
   -26.60852589   57.92041626   -2.98761877   -2.65644455   47.56594469
   100.86522709    0.75907991]
 [  11.44423375    4.88980999   -1.04398927   -2.60535554   12.0765803
    33.81940394    6.8257077    -1.6626198   -47.63162938  -12.24703298
    12.47981864   -1.72094497   29.12852678   63.26463491   90.03822351
   100.51442795    0.76042233]]
[3 1 1 2 3 3 1 1 2 3 1 2 3 3 3 2 3]
TERMINATE: True, GOODNESS: False, SOFT_GOODNESS: True
bad states: [3, 11], Total Reward: 99.12590096574914, Total Steps to terminate: 6
['0:right', '1:down', '2:down', '3:left', '4:right', '5:right', '6:down', '7:down', '8:left', '9:right', '10:down', '11:left', '12:right', '13:right', '14:right', '15:lef
t', '16:right']

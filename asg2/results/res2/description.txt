1000 episodes for reinforce
epsilon = 0.0
using Gn instead of V_est
(basically what is asked for in the assignment, but for 1000 episodes)

results:
REINFORCE results
[[  7.25576075e-144   1.00000000e+000   1.00000000e+000   1.09551554e-045
    2.23928751e-044   1.00055651e-054   8.12095140e-003   6.32769792e-004
    6.37008950e-104   1.00000000e+000   1.00000000e+000   1.38885844e-003
    1.28941246e-057   6.81205461e-043   4.30091270e-091   4.33685107e-003
    4.37332614e-001]
 [  3.71262799e-141   1.00238177e-049   5.33636748e-093   1.77780335e-006
    1.00000000e+000   9.99999978e-001   2.77397770e-050   9.86681154e-001
    1.00000000e+000   3.00474279e-042   1.26238171e-106   1.97120026e-005
    1.00000000e+000   3.73970589e-023   2.53933805e-058   4.26827722e-003
    1.63483561e-001]
 [  4.25096258e-144   4.04368253e-097   8.70712729e-050   9.99774619e-001
    5.45735364e-052   2.24087438e-008   4.93153394e-008   1.26309804e-002
    1.02143179e-099   5.36269915e-077   1.16863136e-100   9.98588758e-001
    1.00043667e-068   1.00000000e+000   5.01071166e-106   9.87062965e-001
    2.32131801e-001]
 [  1.00000000e+000   8.39490152e-098   1.11550856e-094   2.23602971e-004
    2.06705414e-094   1.36447470e-012   9.91878999e-001   5.50960107e-005
    4.90224035e-080   4.04330736e-032   3.49073831e-062   2.67165089e-006
    2.10328494e-047   2.61226543e-064   1.00000000e+000   4.33190698e-003
    1.67052024e-001]]
rounded policy:
[[ 0.   1.   1.   0.   0.   0.   0.   0.   0.   1.   1.   0.   0.   0.   0.
   0.   0.4]
 [ 0.   0.   0.   0.   1.   1.   0.   1.   1.   0.   0.   0.   1.   0.   0.
   0.   0.2]
 [ 0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   1.   0.   1.   0.
   1.   0.2]
 [ 1.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   1.
   0.   0.2]]
argmax policy:
[3 0 0 2 1 1 3 1 1 0 0 2 1 2 3 2 0]
TERMINATE: False, GOODNESS: False, SOFT_GOODNESS: False
bad states: [1, 2, 3, 5, 10, 11, 12, 13], Total Reward: -454.11174619945047, Total Steps to terminate: 100
['0:right', '1:up', '2:up', '3:left', '4:down', '5:down', '6:right', '7:down', '8:down', '9:up', '10:up', '11:left', '12:down', '13:left', '14:right', '15:left', '16:up']

Number of terminations: 16
last 10 episode rewards: [ -21.55063242  -28.59912241  -23.32870433  -27.25202642 -288.12863351
  -30.51451272  -22.48511946  -21.77110936  -18.33561435  -18.03582495]

model-based RL results
[  61.56695163   67.08326836   73.59576481   78.79454653   57.62665866
   63.30909394   79.75310978   85.47051068   46.62783992    7.14789113
   87.0343203    92.9714402    54.99252221   60.50748973   91.42480021
  100.63391522    0.55952344]
[3 3 3 1 3 0 1 1 1 3 3 1 3 3 3 2 1]
rounded policy:
[3 3 3 1 3 0 1 1 1 3 3 1 3 3 3 2 1]
TERMINATE: True, GOODNESS: True, SOFT_GOODNESS: True
bad states: None, Total Reward: 98.70943200820423, Total Steps to terminate: 6
['0:right', '1:right', '2:right', '3:down', '4:right', '5:up', '6:down', '7:down', '8:down', '9:right', '10:right', '11:down', '12:right', '13:right', '14:right', '15:lef
t', '16:down']

Q-learning results
[[  -2.86152914   -0.24776397   -1.85538085   -2.04081174   -2.57087247
    -0.93064062   -1.08404037    4.03363663   -1.38279376  -71.13665044
    18.78242451   26.96781019   -1.83428782  -67.75380328   31.71594502
   100.0407119     0.5480065 ]
 [  -1.49234354    6.28497155   -2.04229162   17.18988634   -2.67172905
   -39.1980434    31.89616056   46.41162037  -18.42129908  -71.5119525
    -0.98215781   85.05300444    0.30131808   -1.54551188   -2.03036272
   100.60646767    0.41488938]
 [  -1.94614724    0.55159345   -1.91126868   -1.70466628   -2.93103488
    -2.28098879   -1.878245     -1.86201854   -3.27372702  -71.65504408
   -57.18783017   35.16982265   -3.85907799  -17.21298563   -1.43667498
   100.5513632     0.46012129]
 [   0.77781144   -0.7620206     5.68629032   -1.72474578    5.27420668
    16.03283736   22.336193     12.14113746  -22.60823559  -42.01707993
    44.79622028   62.18401099   -1.22642377   26.14233705   80.98135969
   100.50605382    0.29845503]]
[3 1 3 1 3 3 1 1 0 3 3 1 1 3 3 1 0]
TERMINATE: True, GOODNESS: False, SOFT_GOODNESS: True
bad states: [12], Total Reward: 95.51770239491113, Total Steps to terminate: 6
['0:right', '1:down', '2:right', '3:down', '4:right', '5:right', '6:down', '7:down', '8:up', '9:right', '10:right', '11:down', '12:down', '13:right', '14:right', '15:down
', '16:up']

next use V_est
and make learning rate constant
lr = 0.01*int((nEpisodes-episode_idx)/(nEpisodes/10)+1)
epsilon = (nEpisodes-episode_idx)/(4.*nEpisodes)

results:
REINFORCE results
[[  6.90679144e-22   3.73954372e-03   1.34820691e-03   6.41358664e-06
    2.96335597e-23   1.00000000e+00   9.64522858e-03   1.59514027e-03
    1.07149736e-32   2.97067668e-34   7.51289228e-03   2.29652289e-03
    2.29672318e-17   5.45680663e-08   4.19838504e-04   3.83298460e-03
    3.30456367e-02]
 [  1.29693597e-21   2.00669535e-04   6.38160688e-03   9.88025002e-01
    1.10476583e-49   3.26579680e-32   9.87129270e-01   2.16743317e-02
    1.00000000e+00   7.16278286e-31   1.37326379e-02   9.95803132e-01
    1.65287744e-18   9.98134356e-01   2.92138419e-03   2.45447281e-03
    1.28108912e-03]
 [  1.49441371e-39   3.52967478e-03   3.31852624e-04   5.87072973e-03
    2.02065175e-21   7.96542958e-39   2.54697574e-03   9.72026053e-01
    1.57456517e-31   9.21773520e-57   2.25175603e-04   1.17597720e-03
    1.00000000e+00   9.36283652e-04   6.69237328e-03   1.95242691e-02
    9.60013965e-01]
 [  1.00000000e+00   9.92530112e-01   9.91938334e-01   6.09785453e-03
    1.00000000e+00   1.45701683e-19   6.78526017e-04   4.70447536e-03
    4.34761569e-60   1.00000000e+00   9.78529294e-01   7.24368003e-04
    1.07110384e-19   9.29305478e-04   9.89966404e-01   9.74188274e-01
    5.65930926e-03]]
rounded policy:
[[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.]
 [ 1.  1.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.]]
argmax policy:
[3 3 3 1 3 0 1 2 1 3 3 1 2 1 3 3 2]
TERMINATE: True, GOODNESS: False, SOFT_GOODNESS: True
bad states: [7, 12, 13], Total Reward: 92.30812888144536, Total Steps to terminate: 8
['0:right', '1:right', '2:right', '3:down', '4:right', '5:up', '6:down', '7:left', '8:down', '9:right', '10:right', '11:down', '12:left', '13:down', '14:right', '15:right
', '16:left']
Number of terminations: 99
last 10 episode rewards: [ 43.08188207  53.40717925  54.60687605  41.00757875  30.35498191
  73.01792607  55.86069987  61.76980938  58.04050067  27.30038728]

model-based RL results
[  6.15193475e+01   6.66769773e+01   7.19850144e+01   7.64122921e+01
   6.27266632e+01   6.85861088e+01   7.83571470e+01   8.40831239e+01
   6.05150488e+01   8.09607509e+00   8.44895544e+01   9.17659846e+01
   7.33942519e+01   8.47262900e+01   9.30907574e+01   1.00162680e+02
   8.65071006e-02]
[3 3 1 1 3 3 1 1 1 3 3 1 3 3 3 0 0]
rounded policy:
[3 3 1 1 3 3 1 1 1 3 3 1 3 3 3 0 0]
TERMINATE: True, GOODNESS: True, SOFT_GOODNESS: True
bad states: None, Total Reward: 92.94997958715655, Total Steps to terminate: 6
['0:right', '1:right', '2:down', '3:down', '4:right', '5:right', '6:down', '7:down', '8:down', '9:right', '10:right', '11:down', '12:right', '13:right', '14:right', '15:u
p', '16:up']

Q-learning results
[[ -2.06912212e+00  -4.16312579e-01   2.50724386e+01  -1.68407155e+00
   -1.43794275e+00   1.73976356e+01   2.44703542e+01   1.07888865e+00
   -6.66071981e+00  -7.09574230e+01   2.58640899e+01   6.82163250e+01
    1.43152037e+00  -3.53718397e+01  -3.10645998e-02   9.99485031e+01
    2.64638644e+00]
 [  1.33432946e+00  -2.20247917e+00   5.20671943e+01   4.62844113e+01
   -3.41450318e+00  -2.70957680e+01   6.45619210e+01   8.44393663e+01
   -1.31210855e+01  -4.07182594e+01   4.06139303e+01   9.37885972e+01
   -3.04849424e+00  -1.36629862e+00  -1.06981999e+00   1.02621201e+02
    2.65036240e+00]
 [ -3.38770184e+00   1.87654525e+00   1.67287154e+01  -2.08387783e+00
   -3.46532730e+00  -1.28986483e+01   1.84017413e+00   4.73030438e+01
   -4.04008723e+00  -7.09572503e+01   9.70981540e+00   8.97081531e+01
   -2.09591673e+00  -1.51425292e+00  -2.04968079e+00   1.02596866e+02
    2.65147584e+00]
 [  2.30304897e+01   3.36767687e+01   5.08680320e+00   1.19746187e+01
    4.64425476e+00  -1.48646412e+01   7.19896041e+01   1.38166481e+01
   -3.01393980e+01  -7.04410429e+01   8.45309116e+01   7.86666652e+01
   -4.44936966e+00   5.93538605e+01   9.29126234e+01   1.02291193e+02
    2.65272959e+00]]
[3 3 1 1 3 0 3 1 2 1 3 1 0 3 3 1 3]
TERMINATE: True, GOODNESS: False, SOFT_GOODNESS: True
bad states: [12], Total Reward: 94.03067712475767, Total Steps to terminate: 6
['0:right', '1:right', '2:down', '3:down', '4:right', '5:up', '6:right', '7:down', '8:left', '9:down', '10:right', '11:down', '12:up', '13:right', '14:right', '15:down',
'16:right']

next keep Gn
and make learning rate constant
lr = 0.01*int((nEpisodes-episode_idx)/(nEpisodes/10)+1)
epsilon = (nEpisodes-episode_idx)/(4.*nEpisodes)

results:
REINFORCE results
[[  2.33682680e-02   8.44776895e-03   5.62302160e-03   1.57064083e-04
    3.34435673e-02   1.11781139e-02   1.31909533e-02   1.35699262e-03
    9.97618308e-01   3.56399388e-05   7.42540342e-04   8.02452220e-03
    6.49038215e-14   9.65924973e-01   1.01635173e-02   1.79364048e-03
    8.28220137e-02]
 [  9.70140769e-01   6.19997506e-03   9.77028268e-01   9.92800403e-01
    2.19877272e-02   5.11738717e-03   2.77268426e-02   9.92532291e-01
    1.02018467e-06   7.95624411e-04   4.13732784e-04   9.22187409e-01
    5.70515139e-24   1.15034343e-02   1.02357044e-02   1.46870676e-02
    8.55822603e-01]
 [  1.76329780e-03   8.33739427e-01   9.39953732e-03   3.87838741e-03
    6.41242791e-02   6.37749673e-02   9.07054468e-02   2.60474430e-03
    1.75960065e-03   7.22595425e-06   5.01389278e-05   3.37143102e-03
    4.35103732e-12   8.27734152e-05   7.49409076e-03   3.39018864e-02
    3.19362729e-02]
 [  4.72766559e-03   1.51612829e-01   7.94917286e-03   3.16414517e-03
    8.80444426e-01   9.19929532e-01   8.68376757e-01   3.50597214e-03
    6.21070746e-04   9.99161510e-01   9.98793588e-01   6.64166380e-02
    1.00000000e+00   2.24888193e-02   9.72106688e-01   9.49617406e-01
    2.94191109e-02]]
rounded policy:
[[ 0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   1.   0.
   0.   0.1]
 [ 1.   0.   1.   1.   0.   0.   0.   1.   0.   0.   0.   0.9  0.   0.   0.
   0.   0.9]
 [ 0.   0.8  0.   0.   0.1  0.1  0.1  0.   0.   0.   0.   0.   0.   0.   0.
   0.   0. ]
 [ 0.   0.2  0.   0.   0.9  0.9  0.9  0.   0.   1.   1.   0.1  1.   0.   1.
   0.9  0. ]]
argmax policy:
[1 2 1 1 3 3 3 1 0 3 3 1 3 0 3 3 1]
TERMINATE: True, GOODNESS: False, SOFT_GOODNESS: False
bad states: [1, 13], Total Reward: 94.28914777454241, Total Steps to terminate: 9
['0:down', '1:left', '2:down', '3:down', '4:right', '5:right', '6:right', '7:down', '8:up', '9:right', '10:right', '11:down', '12:right', '13:up', '14:right', '15:right',
 '16:down']
Number of terminations: 100
last 10 episode rewards: [ 49.86610412  31.66870738  44.75425818  34.26909394  56.0204979
   5.64291593  38.15518518  63.87259263  67.94598776  61.99785905]

model-based RL results
[  6.05790670e+01   6.63993023e+01   7.31849548e+01   7.82462864e+01
   5.81257214e+01   6.34120809e+01   7.90968547e+01   8.47258281e+01
   5.63664740e+01   5.11534115e+00   8.42341817e+01   9.22294263e+01
   6.47476817e+01   7.09556517e+01   8.04054584e+01   1.00127941e+02
   7.52748060e-02]
[3 3 1 1 3 3 3 1 1 3 3 1 3 3 0 0 0]
rounded policy:
[3 3 1 1 3 3 3 1 1 3 3 1 3 3 0 0 0]
TERMINATE: True, GOODNESS: False, SOFT_GOODNESS: True
bad states: [14], Total Reward: 93.02335544013806, Total Steps to terminate: 8
['0:right', '1:right', '2:down', '3:down', '4:right', '5:right', '6:right', '7:down', '8:down', '9:right', '10:right', '11:down', '12:right', '13:right', '14:up', '15:up'
, '16:up']

Q-learning results
[[  -2.19311159    1.91945442   12.62540674   -0.31784621    1.31354288
     8.4281397    12.67424514    3.04912286  -15.46020913  -70.98724841
    10.30543876   22.96770871   -1.66924644  -35.80432323   54.86775387
     0.            0.49506836]
 [  -1.92039979    2.52686516   29.36900603   -0.34566909   -2.96674718
   -35.42142098   48.52836132   -1.2053306    -2.00565519   -3.18194361
    70.19634636   -1.95380495   -1.44761865   72.28712248   46.09342067
   100.52756074    0.49403194]
 [  -1.7482612     1.14249307    4.98853051   17.62510501   -2.63471667
   -10.54529071   -0.90750132   31.27419229   -2.51204139  -71.79443641
   -18.09525439   -2.47543727   -1.80654245   -2.2469646    42.23365314
   100.42912617    0.54201388]
 [   6.98778668   15.51834757    4.04983531   -1.19763113   -2.62325884
    -2.78397977   19.05054306   -1.75074869   -2.76341295  -41.57463519
     2.38258728   -1.67047783   50.58470804    0.           90.64963993
   100.18897316    0.46402977]]
[3 3 1 2 0 0 1 2 1 1 1 0 3 1 3 1 2]
TERMINATE: True, GOODNESS: False, SOFT_GOODNESS: True
bad states: [3, 4, 7, 11, 13], Total Reward: 87.39887631451853, Total Steps to terminate: 10
['0:right', '1:right', '2:down', '3:left', '4:up', '5:up', '6:down', '7:left', '8:down', '9:down', '10:down', '11:up', '12:right', '13:down', '14:right', '15:down', '16:l
eft']

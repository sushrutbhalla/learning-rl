{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I performed cross validation on the learning rate's hyper parameter tuning. I tried different learning rate decay schedules and compare them using the cumulative reward. The following image shows the result of using constant learning rate vs decaying learning rate and the results are compared to the baseline qLearning results. The constant learning rate of value $0.002$ performed the best in my simulations and hence is what I have chosen to display the final results. The \"opt 1\" learning rate decay option starts at $0.01$ and reduces the learning rate by $0.001$ every 20 steps. The \"opt 2\" learning rate decay option starts the learning rate at $0.004$ and decreases the learning rate by $0.001$ after every 60 steps. The \"opt 3\" learning rate decay option starts the learning rate at $0.003$ and decreases the learning rate by $0.001$ after every 60 steps. We see that \"opt 2\" performs nearly as well as a constant learning rate of $0.002$, however \"opt 2\" learning rate showed a faster convergence initially, but a slow improvement as time was increased. Based on the current slope of curves at 200 episodes, it seems that a constant learning rate of $0.002$ would have the best chance of achieving convergence. However, \"opt 2\" should start improving as the policy parameters slowing shift in the right direction and based on its faster improvement in results (cumulative reward) it should be the better choice v/s the constant learning rate of $0.002$ in real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](results/res18/maze_avg_cumulative_reward_part1.png \"Maze: Avg Cumulative reward\")\n",
    "![alt text](results/res18/maze_smooth_n5_avg_cumulative_reward_part1.png \"Maze: (Smooth(n=5) Avg Cumulative reward\")\n",
    "![alt text](results/res18/maze_smooth_n10_avg_cumulative_reward_part1.png \"Maze: (Smooth(n=10) Avg Cumulative reward\")\n",
    "![alt text](results/res18/maze_smooth_n20_avg_cumulative_reward_part1.png \"Maze: (Smooth(n=20) Avg Cumulative reward\")\n",
    "![alt text](results/res18/maze_smooth_n50_avg_cumulative_reward_part1.png \"Maze: (Smooth(n=50) Avg Cumulative reward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell shows the results of using a learning rate of constant $0.001$. The REINFORCE algorithm shows a linear improvement which is very slow and doesn't achieve the best result (cumulative reward) in 200 episodes. With larger number of episodes a constant learning rate of $0.001$ could have achieved better results than other learning rate techinques, however, algorithms should converge faster as samples in real-world environments are not cheap and a smaller sample complexity is highly desired in state of the art algorithms. Thus \"opt 2\" would be the best learning rate decay schedule which should be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](results/res15/maze_avg_cumulative_reward_part1.png \"Maze: Avg Cumulative reward\")\n",
    "![alt text](results/res15/maze_smooth_n5_avg_cumulative_reward_part1.png \"Maze: (Smooth(n=5) Avg Cumulative reward\")\n",
    "![alt text](results/res15/maze_smooth_n10_avg_cumulative_reward_part1.png \"Maze: (Smooth(n=10) Avg Cumulative reward\")\n",
    "![alt text](results/res15/maze_smooth_n20_avg_cumulative_reward_part1.png \"Maze: (Smooth(n=20) Avg Cumulative reward\")\n",
    "![alt text](results/res15/maze_smooth_n50_avg_cumulative_reward_part1.png \"Maze: (Smooth(n=50) Avg Cumulative reward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
